{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e638d667",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "- pip install dash pandas lxml nb_black dash-bootstrap-components\n",
    "- download card_list.csv from 17Lands\n",
    "- save each set as a different page under one dir. Filename should be `data/{set}_card_ratings.html` https://17lands-public.s3.amazonaws.com/analysis_data/cards/card_list.csv\n",
    "- start this jupyter notebook (making sure the card_list and set data are in `data/`)\n",
    "- update the path to your log file (can be found in 17Lands client)\n",
    "- go to `localhost:8050/` to see the app!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c7324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install nb_black\n",
    "# ! pip install dash-bootstrap-components\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f32644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from typing import List, Sequence, Union, Optional, Dict, Any, Tuple\n",
    "import datetime\n",
    "\n",
    "import plotly\n",
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.dependencies import Input, Output\n",
    "from dash import dash_table\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from mtga_follower import (\n",
    "    Follower,\n",
    "    API_ENDPOINT,\n",
    "    get_config,\n",
    "    JSON_START_REGEX,\n",
    "    extract_time,\n",
    "    json_value_matches,\n",
    "    get_rank_string,\n",
    "    logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9532f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1414f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DashFollower(Follower):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.pack_number = \"\"\n",
    "        self.pick_number = \"\"\n",
    "\n",
    "    def _Follower__retry_post(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        We don't want to mess anything up, so don't talk to the API at all\n",
    "        \"\"\"\n",
    "        r = requests.Response()\n",
    "        r.status_code = 200\n",
    "        return r\n",
    "\n",
    "    def _Follower__handle_bot_draft_pack(self, json_obj: Dict[str, Any]):\n",
    "        super()._Follower__handle_bot_draft_pack(json_obj)\n",
    "        self.pick_options = [int(x) for x in json_obj[\"DraftPack\"]]\n",
    "\n",
    "    def _Follower__handle_bot_draft_pick(self, json_obj: Dict[str, Any]):\n",
    "        super()._Follower__handle_bot_draft_pick(json_obj)\n",
    "        self.pack_number = json_obj[\"PackNumber\"]\n",
    "        self.pick_number = json_obj[\"PickNumber\"]\n",
    "        if not hasattr(self, \"pool_card_ids\"):\n",
    "            self.pool_card_ids = []\n",
    "        self.pool_card_ids.append(int(json_obj[\"CardId\"]))\n",
    "\n",
    "    def _Follower__handle_joined_pod(self, json_obj: Dict[Any, str]):\n",
    "        self.pick_options = []\n",
    "        self.pool_card_ids = []\n",
    "\n",
    "    def _Follower__handle_blob(self, full_log):\n",
    "        \"\"\"Attempt to parse a complete log message and send the data if relevant.\"\"\"\n",
    "        match = JSON_START_REGEX.search(full_log)\n",
    "        if not match:\n",
    "            return\n",
    "        try:\n",
    "            json_obj, end = self.json_decoder.raw_decode(full_log, match.start())\n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.debug(\n",
    "                f\"Ran into error {e} when parsing at {self.cur_log_time}. Data was: {full_log}\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        json_obj = self._Follower__extract_payload(json_obj)\n",
    "        #         print(json_obj)\n",
    "        if type(json_obj) != dict:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            maybe_time = self._Follower__maybe_get_utc_timestamp(json_obj)\n",
    "            if maybe_time is not None:\n",
    "                self.last_utc_time = maybe_time\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if json_value_matches(\n",
    "            \"Client.Connected\", [\"params\", \"messageName\"], json_obj\n",
    "        ):  # Doesn't exist any more\n",
    "            self._Follower__handle_login(json_obj)\n",
    "        elif \"Event_Join\" in full_log and \"EventName\" in json_obj:\n",
    "            #             print(\"joined event\")\n",
    "            self._Follower__handle_joined_pod(json_obj)\n",
    "        elif \"DraftStatus\" in json_obj:\n",
    "            #             print(\"draft status\")\n",
    "            self._Follower__handle_bot_draft_pack(json_obj)\n",
    "        elif \"BotDraft_DraftPick\" in full_log and \"PickInfo\" in json_obj:\n",
    "            #             print(\"draft pick\")\n",
    "            self._Follower__handle_bot_draft_pick(json_obj[\"PickInfo\"])\n",
    "        elif \"LogBusinessEvents\" in full_log and \"PickGrpId\" in json_obj:\n",
    "            self._Follower__handle_human_draft_combined(json_obj)\n",
    "        elif \"Draft.Notify \" in full_log and \"method\" not in json_obj:\n",
    "            self._Follower__handle_human_draft_pack(json_obj)\n",
    "        elif \"authenticateResponse\" in json_obj:\n",
    "            self._Follower__update_screen_name(\n",
    "                json_obj[\"authenticateResponse\"][\"screenName\"]\n",
    "            )\n",
    "\n",
    "def read_data(\n",
    "    data_path: str,\n",
    "    supported_expansions: List[str] = [\"ZNR\", \"KHM\", \"STX\", \"AFR\", \"MID\", \"VOW\"],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load up the html version of the 17Lands card ratings and stack them. Also\n",
    "    load the card_id mapping and join it\n",
    "    \"\"\"\n",
    "    card_ids_df = pd.read_csv(\n",
    "        os.path.join(data_path, \"card_list.csv\"),\n",
    "        usecols=[\n",
    "            \"id\",\n",
    "            \"expansion\",\n",
    "            \"name\",\n",
    "            \"rarity\",\n",
    "            \"color_identity\",\n",
    "            \"mana_value\",\n",
    "            \"types\",\n",
    "        ],\n",
    "    )\n",
    "    card_ids_df = card_ids_df[card_ids_df.expansion.isin(supported_expansions)]\n",
    "    card_ids_df = card_ids_df[[\"id\", \"expansion\", \"name\", \"types\"]]\n",
    "\n",
    "    ratings_df = None\n",
    "    for set_name in supported_expansions:\n",
    "        single_df = pd.read_html(\n",
    "            os.path.join(data_path, f\"{set_name.lower()}_card_ratings.html\")\n",
    "        )[0]\n",
    "        single_df[\"expansion\"] = set_name.upper()\n",
    "        if ratings_df is None:\n",
    "            ratings_df = single_df\n",
    "        else:\n",
    "            ratings_df = ratings_df.append(single_df)\n",
    "    ratings_df = ratings_df.rename(columns={k: k.lower() for k in ratings_df.columns})\n",
    "\n",
    "    joined = pd.merge(\n",
    "        ratings_df,\n",
    "        card_ids_df,\n",
    "        how=\"left\",\n",
    "        left_on=[\"name\", \"expansion\"],\n",
    "        right_on=[\"name\", \"expansion\"],\n",
    "        suffixes=[\"\", \"_y\"],\n",
    "    )\n",
    "    joined[\"iwd\"] = joined[\"iwd\"].apply(lambda x: float(str(x).replace(\"pp\", \"\")))\n",
    "    return joined.set_index(\"id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878df6d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# logfile = r\"C:\\Users\\thisi\\AppData\\LocalLow\\Wizards Of The Coast\\MTGA\\Player.log\"\n",
    "# token = get_config()\n",
    "# follower = DashFollower(token, API_ENDPOINT)\n",
    "\n",
    "# r = follower.parse_log(logfile, follow=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d99aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d409a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of seconds between refreshes. Needs to be long enough to fully parse your \n",
    "# .log file. If your file is huge, this could be an issue, and you may want to exit\n",
    "# and reload the game\n",
    "N_SECONDS = 10\n",
    "\n",
    "# This is the path to your log file. If you want to test it out, I recommend\n",
    "# saving a copy of one and editing it to have however many events you'd like\n",
    "logfile = r\"C:\\Users\\...\\AppData\\LocalLow\\Wizards Of The Coast\\MTGA\\Player.log\"\n",
    "\n",
    "# This may pop up a dialog the first time, I'm not sure.\n",
    "token = get_config()\n",
    "\n",
    "# This controls what displays. you can print(df) to see your column options\n",
    "useful_cols = [\n",
    "    \"name\",\n",
    "    \"color\",\n",
    "    \"types\",\n",
    "    \"rarity\",\n",
    "    \"alsa\",\n",
    "    \"ata\",\n",
    "    \"oh wr\",\n",
    "    \"gd wr\",\n",
    "    \"iwd\",\n",
    "]\n",
    "\n",
    "# allows you to override the CSS of the dash app\n",
    "external_stylesheets = [\"https://codepen.io/chriddyp/pen/bWLwgP.css\", dbc.themes.GRID]\n",
    "\n",
    "# modify this to change the cell styling in the tables\n",
    "cell_styling = {\"textAlign\": \"left\", \"padding\": \"5px\"}\n",
    "\n",
    "# the core of the app\n",
    "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "app.layout = html.Div(\n",
    "    html.Div(\n",
    "        [\n",
    "            dbc.Container(\n",
    "                [\n",
    "                    dbc.Row(html.H4(\"Current Options\")),\n",
    "                    dbc.Row(html.Div(id=\"live-update-text\")),\n",
    "                    dbc.Row(html.Div(id=\"current-pick-table-holder\")),\n",
    "                    dbc.Row(html.H4(\"Pool So Far\")),\n",
    "                    dbc.Row(html.Div(id=\"pool-table-holder\")),\n",
    "                ]\n",
    "            ),\n",
    "            dcc.Interval(\n",
    "                id=\"interval-component\",\n",
    "                interval=N_SECONDS * 1000,  # in milliseconds\n",
    "                n_intervals=0,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def get_color_count_graph(inp_df: pd.DataFrame) -> plotly.graph_objects.Figure:\n",
    "    \"\"\"\n",
    "    Count the occurences of each \"color\" symbol in the card data's \"color\" column\n",
    "    in the pool of cards you've drafted so far.\n",
    "    \"\"\"\n",
    "    color_counts = (\n",
    "        inp_df.color.apply(lambda x: list(x) if isinstance(x, str) else [])\n",
    "        .explode()\n",
    "        .value_counts()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"Color\", \"color\": \"Count\"})\n",
    "    )\n",
    "    color_hexes = [\"#838383\", \"#26b569\", \"#f85656\", \"#aae0fa\", \"#fef2be\"]\n",
    "    missing_colors = [\n",
    "        c for c in (\"B\", \"G\", \"R\", \"U\", \"W\") if c not in color_counts.Color.values\n",
    "    ]\n",
    "    missing_df = pd.DataFrame(\n",
    "        [[c, 0] for c in missing_colors], columns=[\"Color\", \"Count\"]\n",
    "    )\n",
    "    color_counts.append(missing_df)\n",
    "    color_counts = color_counts.sort_values(\"Color\")\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Bar(name=x[0], x=[x[0]], y=[x[1]], marker_color=color_hexes[i])\n",
    "            for i, x in enumerate(color_counts.values)\n",
    "        ],\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            \"text\": \"Card Color Counts\",\n",
    "            \"y\": 0.9,\n",
    "            \"x\": 0.5,\n",
    "            \"xanchor\": \"center\",\n",
    "            \"yanchor\": \"top\",\n",
    "        }\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def get_type_summary(inp_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Get counts of the core card types and of the other keywords in your \n",
    "    pool of drafted cards so far.\n",
    "    \"\"\"\n",
    "    copied = inp_df.copy()\n",
    "    card_types = [\n",
    "        \"Land\",\n",
    "        \"Artifact\",\n",
    "        \"Creature\",\n",
    "        \"Enchantment\",\n",
    "        \"Planeswalker\",\n",
    "        \"Instant\",\n",
    "        \"Sorcery\",\n",
    "    ]\n",
    "    copied[\"keywords\"] = copied[\"types\"].apply(\n",
    "        lambda x: [t.strip() for t in x.split(\" \") if t.strip() not in (\"\", \"-\")]\n",
    "    )\n",
    "    vc = copied[\"keywords\"].explode().value_counts().reset_index()\n",
    "    main = (\n",
    "        vc[vc[\"index\"].apply(lambda x: x in card_types)]\n",
    "        .copy()\n",
    "        .rename(columns={\"index\": \"type\", \"keywords\": \"count\"})\n",
    "    )\n",
    "    other = (\n",
    "        vc[~vc[\"index\"].apply(lambda x: x in card_types)]\n",
    "        .copy()\n",
    "        .rename(columns={\"index\": \"keyword\", \"keywords\": \"count\"})\n",
    "    )\n",
    "    return main, other\n",
    "\n",
    "\n",
    "def get_pool_summary(inp_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Return all of the summary objects:\n",
    "      - color count graph\n",
    "      - type count df\n",
    "      - keyword count df\n",
    "    \"\"\"\n",
    "    color_count_graph = get_color_count_graph(inp_df)\n",
    "    main_type_sum, other_type_sum = get_type_summary(inp_df)\n",
    "    return color_count_graph, main_type_sum, other_type_sum\n",
    "\n",
    "\n",
    "# every N seconds, our Interval fires, and we update most of the app\n",
    "# by parsing the log\n",
    "@app.callback(\n",
    "    [\n",
    "        Output(\"live-update-text\", \"children\"),\n",
    "        Output(\"current-pick-table-holder\", \"children\"),\n",
    "        Output(\"pool-table-holder\", \"children\"),\n",
    "    ],\n",
    "    Input(\"interval-component\", \"n_intervals\"),\n",
    ")\n",
    "def update_metrics(n):\n",
    "    \"\"\"\n",
    "    Update the whole app by parsing the log file\n",
    "    \"\"\"\n",
    "    # create a 17Lands client with the API interaction removed\n",
    "    follower = DashFollower(token, API_ENDPOINT)\n",
    "    # parse your whole log\n",
    "    r = follower.parse_log(logfile, follow=False)\n",
    "    \n",
    "    style = {\"padding\": \"5px\", \"fontSize\": \"16px\"}\n",
    "    # get the cards available to be picked\n",
    "    picked_df = df.loc[getattr(follower, \"pick_options\", []), useful_cols].sort_values(\n",
    "        \"iwd\", ascending=False\n",
    "    )\n",
    "    # get the cards you've already drafted\n",
    "    pool_df = df.loc[getattr(follower, \"pool_card_ids\", []), useful_cols].sort_values(\n",
    "        \"iwd\", ascending=False\n",
    "    )\n",
    "    # turn them both into Table objects\n",
    "    pick_table = html.Div(\n",
    "        dash_table.DataTable(\n",
    "            id=\"pick_table\",\n",
    "            columns=[{\"name\": i, \"id\": i} for i in picked_df.columns],\n",
    "            data=picked_df.to_dict(\"records\"),\n",
    "            style_cell=cell_styling,\n",
    "        ),\n",
    "        style={\"width\": \"80%\", \"margin\": \"auto\"},\n",
    "    )\n",
    "    pool_table = html.Div(\n",
    "        dash_table.DataTable(\n",
    "            id=\"pool_table\",\n",
    "            columns=[{\"name\": i, \"id\": i} for i in pool_df.columns],\n",
    "            data=pool_df.to_dict(\"records\"),\n",
    "            style_cell=cell_styling,\n",
    "        )\n",
    "    )\n",
    "    # get the summary statistics for your pool\n",
    "    pool_summary, main_type_sum, other_type_sum = get_pool_summary(pool_df)\n",
    "    main_type_sum = dash_table.DataTable(\n",
    "        id=\"main_type_table\",\n",
    "        columns=[{\"name\": i, \"id\": i} for i in main_type_sum.columns],\n",
    "        data=main_type_sum.to_dict(\"records\"),\n",
    "        style_cell=cell_styling,\n",
    "    )\n",
    "    other_type_sum = dash_table.DataTable(\n",
    "        id=\"other_type_table\",\n",
    "        columns=[{\"name\": i, \"id\": i} for i in other_type_sum.columns],\n",
    "        data=other_type_sum.to_dict(\"records\"),\n",
    "        style_cell=cell_styling,\n",
    "    )\n",
    "    # update the container with the summary info\n",
    "    curr_div = dbc.Container(\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(pool_table, width={\"size\": 8}),\n",
    "                dbc.Col(\n",
    "                    [\n",
    "                        dbc.Row(dcc.Graph(figure=pool_summary)),\n",
    "                        dbc.Row(main_type_sum),\n",
    "                        dbc.Row(html.Div(\"--\")),\n",
    "                        dbc.Row(other_type_sum),\n",
    "                    ],\n",
    "                    width={\"size\": 4},\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return [\n",
    "        html.Span(\n",
    "            f\"Pack {follower.pack_number}, Pick {follower.pick_number}\", style=style\n",
    "        ),\n",
    "        pick_table,\n",
    "        curr_div,\n",
    "    ]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2bb9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e26b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6630cdbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00450f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3400319",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7caf2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580d14b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33630d10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
