{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e638d667",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "- pip install dash pandas lxml nb_black dash-bootstrap-components\n",
    "- download card_list.csv from 17Lands https://17lands-public.s3.amazonaws.com/analysis_data/cards/card_list.csv\n",
    "- save each set as a different page under one dir. Filename should be `data/{set}_card_ratings.html` \n",
    "- start this jupyter notebook (making sure the card_list and set data are in `data/`)\n",
    "- update the path to your log file (can be found in 17Lands client)\n",
    "- go to `localhost:8050/` to see the app!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c7324",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f32644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from typing import List, Sequence, Union, Optional, Dict, Any, Tuple\n",
    "import datetime\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly\n",
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.dependencies import Input, Output\n",
    "from dash import dash_table\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from flask import Flask\n",
    "\n",
    "from mtga_draft_helper.follower_logic import (\n",
    "    DashFollower,\n",
    "    ALSATrackerType,\n",
    "    ColorTrackerType,\n",
    "    get_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1414f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(\n",
    "    data_path: str,\n",
    "    supported_expansions: List[str] = [\"ZNR\", \"KHM\", \"STX\", \"AFR\", \"MID\", \"VOW\"],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load up the html version of the 17Lands card ratings and stack them. Also\n",
    "    load the card_id mapping and join it\n",
    "    \"\"\"\n",
    "    card_ids_df = pd.read_csv(\n",
    "        os.path.join(data_path, \"card_list.csv\"),\n",
    "        usecols=[\n",
    "            \"id\",\n",
    "            \"expansion\",\n",
    "            \"name\",\n",
    "            \"rarity\",\n",
    "            \"color_identity\",\n",
    "            \"mana_value\",\n",
    "            \"types\",\n",
    "        ],\n",
    "    )\n",
    "    card_ids_df = card_ids_df[card_ids_df.expansion.isin(supported_expansions)]\n",
    "    card_ids_df = card_ids_df[[\"id\", \"expansion\", \"name\", \"types\"]]\n",
    "\n",
    "    ratings_df = None\n",
    "    for set_name in supported_expansions:\n",
    "        single_df = pd.read_html(\n",
    "            os.path.join(data_path, f\"{set_name.lower()}_card_ratings.html\")\n",
    "        )[0]\n",
    "        single_df[\"expansion\"] = set_name.upper()\n",
    "        if ratings_df is None:\n",
    "            ratings_df = single_df\n",
    "        else:\n",
    "            ratings_df = ratings_df.append(single_df)\n",
    "    ratings_df = ratings_df.rename(columns={k: k.lower() for k in ratings_df.columns})\n",
    "\n",
    "    joined = pd.merge(\n",
    "        ratings_df,\n",
    "        card_ids_df,\n",
    "        how=\"left\",\n",
    "        left_on=[\"name\", \"expansion\"],\n",
    "        right_on=[\"name\", \"expansion\"],\n",
    "        suffixes=[\"\", \"_y\"],\n",
    "    )\n",
    "    joined[\"iwd\"] = joined[\"iwd\"].apply(lambda x: float(str(x).replace(\"pp\", \"\")))\n",
    "    return joined.set_index(\"id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878df6d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff6bc11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d409a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a463e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# number of seconds between refreshes. Needs to be long enough to fully parse your\n",
    "# .log file. If your file is huge, this could be an issue, and you may want to exit\n",
    "# and reload the game\n",
    "N_SECONDS = 6\n",
    "\n",
    "# threshold for (pick_num - ALSA) at which we consider a\n",
    "# card to be signifying some amount of \"openness\" of that\n",
    "# color in the draft\n",
    "LATE_ALSA_DIFF_THRESHOLD = 0.5\n",
    "\n",
    "# if we see cards that show up \"late\" that are multicolor,\n",
    "# how much should we weight this as an indicator that\n",
    "# each of their colors is open?\n",
    "MULTICOLOR_ALSA_DIFF_FACTOR = 0.5\n",
    "\n",
    "# This is the path to your log file. If you want to test it out, I recommend\n",
    "# saving a copy of one and editing it to have however many events you'd like\n",
    "logfile = os.path.join(\n",
    "    Path.home(),\n",
    "    r\"AppData\\LocalLow\\Wizards Of The Coast\\MTGA\\Player.log\",\n",
    ")\n",
    "\n",
    "print(f\"looking for logfile at: {logfile}\")\n",
    "\n",
    "# This may pop up a dialog the first time, I'm not sure.\n",
    "token = get_config()\n",
    "\n",
    "# This controls what displays. you can print(df) to see your column options\n",
    "useful_cols = [\n",
    "    \"name\",\n",
    "    \"color\",\n",
    "    \"types\",\n",
    "    \"rarity\",\n",
    "    \"alsa\",\n",
    "    \"ata\",\n",
    "    \"oh wr\",\n",
    "    \"gd wr\",\n",
    "    \"iwd\",\n",
    "]\n",
    "\n",
    "# allows you to override the CSS of the dash app\n",
    "external_stylesheets = [\"https://codepen.io/chriddyp/pen/bWLwgP.css\", dbc.themes.GRID]\n",
    "\n",
    "# modify this to change the cell styling in the tables\n",
    "cell_styling = {\"textAlign\": \"left\", \"padding\": \"5px\"}\n",
    "\n",
    "# making server explicit so that eventually a Follower object could\n",
    "# run separately and just post relevant events to an event API\n",
    "# flask_app = Flask(__name__)\n",
    "\n",
    "# the core of the app\n",
    "app = dash.Dash(\n",
    "    __name__,\n",
    "    #     server=flask_app,\n",
    "    #     url_base_pathname=\"/dash/\",\n",
    "    external_stylesheets=external_stylesheets,\n",
    ")\n",
    "app.layout = html.Div(\n",
    "    html.Div(\n",
    "        [\n",
    "            dbc.Container(\n",
    "                [\n",
    "                    dbc.Row(html.H4(\"Current Options\")),\n",
    "                    dbc.Row(html.Div(id=\"live-update-text\")),\n",
    "                    dbc.Row(html.Div(id=\"current-pick-table-holder\")),\n",
    "                    dbc.Row(html.H4(\"Draft Info\")),\n",
    "                    dbc.Row(html.Div(id=\"draft-tracking-info\")),\n",
    "                    dbc.Row(html.H4(\"Pool So Far\")),\n",
    "                    dbc.Row(html.Div(id=\"pool-table-holder\")),\n",
    "                ]\n",
    "            ),\n",
    "            dcc.Interval(\n",
    "                id=\"interval-component\",\n",
    "                interval=N_SECONDS * 1000,  # in milliseconds\n",
    "                n_intervals=0,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "# init an ALSA tracker\n",
    "local_alsa_tracker: ALSATrackerType = {}\n",
    "local_color_tracker: ColorTrackerType = {}\n",
    "\n",
    "\n",
    "def get_color_count_graph(inp_df: pd.DataFrame) -> plotly.graph_objects.Figure:\n",
    "    \"\"\"\n",
    "    Count the occurences of each \"color\" symbol in the card data's \"color\" column\n",
    "    in the pool of cards you've drafted so far.\n",
    "    \"\"\"\n",
    "    color_counts = (\n",
    "        inp_df.color.apply(lambda x: list(x) if isinstance(x, str) else [])\n",
    "        .explode()\n",
    "        .value_counts()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"Color\", \"color\": \"Count\"})\n",
    "    )\n",
    "    color_hexes = [\"#838383\", \"#26b569\", \"#f85656\", \"#aae0fa\", \"#fef2be\"]\n",
    "    missing_colors = [\n",
    "        c for c in (\"B\", \"G\", \"R\", \"U\", \"W\") if c not in color_counts.Color.values\n",
    "    ]\n",
    "    missing_df = pd.DataFrame(\n",
    "        [[c, 0] for c in missing_colors], columns=[\"Color\", \"Count\"]\n",
    "    )\n",
    "    color_counts.append(missing_df)\n",
    "    color_counts = color_counts.sort_values(\"Color\")\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Bar(name=x[0], x=[x[0]], y=[x[1]], marker_color=color_hexes[i])\n",
    "            for i, x in enumerate(color_counts.values)\n",
    "        ],\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            \"text\": \"Card Color Counts\",\n",
    "            \"y\": 0.9,\n",
    "            \"x\": 0.5,\n",
    "            \"xanchor\": \"center\",\n",
    "            \"yanchor\": \"top\",\n",
    "        }\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def get_type_summary(inp_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Get counts of the core card types and of the other keywords in your\n",
    "    pool of drafted cards so far.\n",
    "    \"\"\"\n",
    "    copied = inp_df.copy()\n",
    "    card_types = [\n",
    "        \"Land\",\n",
    "        \"Artifact\",\n",
    "        \"Creature\",\n",
    "        \"Enchantment\",\n",
    "        \"Planeswalker\",\n",
    "        \"Instant\",\n",
    "        \"Sorcery\",\n",
    "    ]\n",
    "    copied[\"keywords\"] = copied[\"types\"].apply(\n",
    "        lambda x: [t.strip() for t in x.split(\" \") if t.strip() not in (\"\", \"-\")]\n",
    "    )\n",
    "    vc = copied[\"keywords\"].explode().value_counts().reset_index()\n",
    "    main = (\n",
    "        vc[vc[\"index\"].apply(lambda x: x in card_types)]\n",
    "        .copy()\n",
    "        .rename(columns={\"index\": \"type\", \"keywords\": \"count\"})\n",
    "    )\n",
    "    other = (\n",
    "        vc[~vc[\"index\"].apply(lambda x: x in card_types)]\n",
    "        .copy()\n",
    "        .rename(columns={\"index\": \"keyword\", \"keywords\": \"count\"})\n",
    "    )\n",
    "    return main, other\n",
    "\n",
    "\n",
    "def get_draft_level_info(\n",
    "    alsa_tracker: ALSATrackerType, color_tracker: ColorTrackerType\n",
    "):\n",
    "    # handle the color tracking\n",
    "    color_df = pd.DataFrame(\n",
    "        [[k, v] for k, v in color_tracker.items()],\n",
    "        columns=[\"color\", \"cards passed to you\"],\n",
    "    ).sort_values(\"color\")\n",
    "\n",
    "    # handle the ALSA tracking\n",
    "    alsa_diff_sums = {\"B\": 0, \"G\": 0, \"R\": 0, \"U\": 0, \"W\": 0}\n",
    "    for key, alsa_diff_dict in alsa_tracker.items():\n",
    "        for inner_color, val in alsa_diff_dict.items():\n",
    "            alsa_diff_sums[inner_color] += np.sum(val)\n",
    "    alsa_df = pd.DataFrame(\n",
    "        [[k, v] for k, v in alsa_diff_sums.items()],\n",
    "        columns=[\"color\", \"ALSA difference sum\"],\n",
    "    )\n",
    "    return color_df, alsa_df\n",
    "\n",
    "\n",
    "def get_pool_summary(inp_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Return all of the summary objects:\n",
    "      - color count graph\n",
    "      - type count df\n",
    "      - keyword count df\n",
    "    \"\"\"\n",
    "    color_count_graph = get_color_count_graph(inp_df)\n",
    "    main_type_sum, other_type_sum = get_type_summary(inp_df)\n",
    "    return color_count_graph, main_type_sum, other_type_sum\n",
    "\n",
    "\n",
    "# every N seconds, our Interval fires, and we update most of the app\n",
    "# by parsing the log\n",
    "@app.callback(\n",
    "    Output(\"live-update-text\", \"children\"),\n",
    "    Output(\"current-pick-table-holder\", \"children\"),\n",
    "    Output(\"draft-tracking-info\", \"children\"),\n",
    "    Output(\"pool-table-holder\", \"children\"),\n",
    "    Input(\"interval-component\", \"n_intervals\"),\n",
    ")\n",
    "def update_metrics(n):\n",
    "    \"\"\"\n",
    "    Update the whole app by parsing the log file\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    # create a 17Lands client with the API interaction removed\n",
    "    # TODO: just fix __init__ to set these\n",
    "    follower = DashFollower(token, \"\")\n",
    "    follower.alsa_tracker = local_alsa_tracker\n",
    "    follower.color_tracker = local_color_tracker\n",
    "    follower.df = df\n",
    "    follower.late_alsa_diff_threshold = LATE_ALSA_DIFF_THRESHOLD\n",
    "    follower.multicolor_alsa_diff_factor = MULTICOLOR_ALSA_DIFF_FACTOR\n",
    "    # parse your whole log\n",
    "    r = follower.parse_log(logfile, follow=False)\n",
    "    t1 = time.time()\n",
    "    print(f\"parsed file in {t1 - t0} seconds\")\n",
    "\n",
    "    color_df, alsa_df = get_draft_level_info(local_alsa_tracker, local_color_tracker)\n",
    "\n",
    "    style = {\"padding\": \"5px\", \"fontSize\": \"16px\"}\n",
    "    # get the cards available to be picked\n",
    "    picked_df = df.loc[getattr(follower, \"pick_options\", []), useful_cols].sort_values(\n",
    "        \"iwd\", ascending=False\n",
    "    )\n",
    "    # get the cards you've already drafted\n",
    "    pool_df = df.loc[getattr(follower, \"pool_card_ids\", []), useful_cols].sort_values(\n",
    "        \"iwd\", ascending=False\n",
    "    )\n",
    "    # turn them both into Table objects\n",
    "    pick_table = html.Div(\n",
    "        dash_table.DataTable(\n",
    "            id=\"pick_table\",\n",
    "            columns=[{\"name\": i, \"id\": i} for i in picked_df.columns],\n",
    "            data=picked_df.to_dict(\"records\"),\n",
    "            style_cell=cell_styling,\n",
    "        ),\n",
    "        style={\"width\": \"80%\", \"margin\": \"auto\"},\n",
    "    )\n",
    "    pool_table = html.Div(\n",
    "        dash_table.DataTable(\n",
    "            id=\"pool_table\",\n",
    "            columns=[{\"name\": i, \"id\": i} for i in pool_df.columns],\n",
    "            data=pool_df.to_dict(\"records\"),\n",
    "            style_cell=cell_styling,\n",
    "        )\n",
    "    )\n",
    "    # get the summary statistics for your pool\n",
    "    pool_summary, main_type_sum, other_type_sum = get_pool_summary(pool_df)\n",
    "    main_type_sum = dash_table.DataTable(\n",
    "        id=\"main_type_table\",\n",
    "        columns=[{\"name\": i, \"id\": i} for i in main_type_sum.columns],\n",
    "        data=main_type_sum.to_dict(\"records\"),\n",
    "        style_cell=cell_styling,\n",
    "    )\n",
    "    other_type_sum = dash_table.DataTable(\n",
    "        id=\"other_type_table\",\n",
    "        columns=[{\"name\": i, \"id\": i} for i in other_type_sum.columns],\n",
    "        data=other_type_sum.to_dict(\"records\"),\n",
    "        style_cell=cell_styling,\n",
    "    )\n",
    "    # update the container with the summary info\n",
    "    curr_div = dbc.Container(\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(pool_table, width={\"size\": 8}),\n",
    "                dbc.Col(\n",
    "                    [\n",
    "                        dbc.Row(dcc.Graph(figure=pool_summary)),\n",
    "                        dbc.Row(main_type_sum),\n",
    "                        dbc.Row(html.Div(\"--\")),\n",
    "                        dbc.Row(other_type_sum),\n",
    "                    ],\n",
    "                    width={\"size\": 4},\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    draft_info_div = dbc.Container(\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(\n",
    "                    dash_table.DataTable(\n",
    "                        columns=[{\"name\": i, \"id\": i} for i in color_df.columns],\n",
    "                        data=color_df.to_dict(\"records\"),\n",
    "                        style_cell=cell_styling,\n",
    "                    ),\n",
    "                    width={\"size\": 4},\n",
    "                ),\n",
    "                dbc.Col(\n",
    "                    dash_table.DataTable(\n",
    "                        columns=[{\"name\": i, \"id\": i} for i in alsa_df.columns],\n",
    "                        data=alsa_df.to_dict(\"records\"),\n",
    "                        style_cell=cell_styling,\n",
    "                    ),\n",
    "                    width={\"size\": 4},\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    print(f\"rebuilt dash components in {time.time() - t1} seconds\")\n",
    "    return [\n",
    "        html.Span(\n",
    "            f\"Pack {follower.pack_number}, Pick {follower.pick_number}\", style=style\n",
    "        ),\n",
    "        pick_table,\n",
    "        draft_info_div,\n",
    "        curr_div,\n",
    "    ]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
